<!DOCTYPE html>
<html lang="{{ site.lang | default: "en-US" }}">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    <link rel="stylesheet" href ="../assets/css/landing.css">
  </head>
  <body>
    <div class="col-md-5">
      <header>
        <h2><a id = "imp" href="../index.html">Home page</a></h2>
       
        <p>Deconstructing Deep Learning +  δeviations</p>
        
        <p>
          Drop me an <a href = "mailto: msubhaditya@gmail.com">email</a>
          | RSS feed link : <a href ="https://subhadityamukherjee.github.io/feed.xml">Click</a><br>
          Format : 
          Date | Title<br>
          &emsp;&emsp;TL; DR<br>
          <h4>Total posts : 82</h4>
          <!-- <div id="search-container"> -->
          <!--   Search for something in the blog <input type="text" id="search-input" placeholder="search..."> -->
          <!-- </div><br> -->
          <!-- <ul id="results-container"></ul> -->
        </p>
        
        
        <p class="view">
        <a href="https://www.github.com/SubhadityaMukherjee">View My GitHub Profile </a>
        </p>
      </header>
      
      <hr>
      <script src="/assets/js/search-script.js" type="text/javascript"></script>
      
      <script>
        SimpleJekyllSearch({
          searchInput: document.getElementById('search-input'),
          resultsContainer: document.getElementById('results-container'),
          json: '/assets/search.json'
        })
        </script>
    </div>
<section>
        <div class=col-md-5>
                <a href = "../deeplearning.html">Index page</a>
                <br>

  <p><h1>Thinking machines - Turing (Just notes)</h1>

</p>
<p><strong>[20]</strong> Thinking machines - Turing (Just notes)
- A. M. TURING, I.—COMPUTING MACHINERY AND INTELLIGENCE, Mind, Volume LIX, Issue 236, October 1950, Pages 433–460, https://doi.org/10.1093/mind/LIX.236.433. <a href="https://oup.silverchair-cdn.com/UI/app/svg/pdf.svg">Paper</a></p>
<h2 id="notes">Notes</h2>
<h1 id="can-machines-think">‘Can machines think?’</h1>
<blockquote>
<p>We can only see a short distance ahead, but we can see plenty there
that needs to be done.</p>
</blockquote>
<ul>
<li>‘imitation game’. It is played with three people, a man
(A), a woman (B), and an interrogator (C) who may be of either sex. The
interrogator stays in a room apart from the other two.</li>
<li>The ideal arrangement is to
have a teleprinter communicating between the two rooms. Alternatively the
question and answers can be repeated by an intermediary. The object of the
game for the third player (B) is to help the interrogator.</li>
<li>‘What will happen when a machine takes
the part of A in this game?’ Will the interrogator decide wrongly as often
when the game is played like this as he does when the game is played
between a man and a woman? These questions replace our original, ‘Can
machines think?’</li>
<li>‘Is this new question a worthy one to investigate?’</li>
<li>The new problem has the advantage of drawing a fairly sharp line
between the physical and the intellectual capacities of a man.</li>
<li>It is possible that at some time this
might be done, but even supposing this invention available we should feel
there was little point in trying to make a ‘thinking machine’ more human
by dressing it up in such artificial flesh. </li>
<li>We do not wish to penalise the machine for its inability to shine in beauty
competitions, nor to penalise a man for losing in a race against an
aeroplane.</li>
<li>The conditions of our game make these disabilities irrelevant.
The ‘witnesses’ can brag, if they consider it advisable, as much as they
please about their charms, strength or heroism, but the interrogator cannot
demand practical demonstrations.</li>
<li>If the man were to try and
pretend to be the machine he would clearly make a very poor showing. He
would be given away at once by slowness and inaccuracy in arithmetic.</li>
<li>May not machines carry out something which ought to be described as
thinking but which is very different from what a man does?</li>
<li>Finally, we wish
to exclude from the machines men born in the usual manner.</li>
<li>team of engineers should be all of one sex, but
this would not really be satisfactory, for it is probably possible to rear a
complete individual from a single cell of the skin (say) of a man.</li>
<li>‘thinking machines’ has been
aroused by a particular kind of machine, usually called an ‘electronic
computer’ or ‘digital computer’. </li>
<li>The short answer is that we are not asking whether all digital
computers would do well in the game nor whether the computers at present
available would do well, but whether there are imaginable computers which
would do well.</li>
<li>The idea behind digital computers may be explained by saying that these
machines are intended to carry out any operations which could be done by
a human computer. </li>
<li>We have mentioned that the ‘book of rules’ supplied to the computer
is replaced in the machine by a part of the store. It is then called the ‘table
of instructions’</li>
<li>Needless to say it would not occur in the machine expressed in
English. It would more likely be coded in a form such as 6809430217.</li>
<li>Instructions of these latter types are very important because they make
it possible for a sequence of operations to be repeated over and over again
until some condition is fulfilled, but in doing so to obey, not fresh
instructions on each repetition, but the same ones over and over again.</li>
<li>The reader must accept it as a fact that digital computers can be
constructed, and indeed have been constructed, according to the principles
we have described, and that they can in fact mimic the actions of a human
computer very closely.</li>
<li>Constructing instruction tables is usually described as
‘programming’.</li>
<li>It is not normally
possible to determine from observing a machine whether it has a random
element, for a similar effect can be produced by such devices as making
the choices depend on the digits of the decimal for π.</li>
<li>Although Babbage had all the essential ideas, his machine was
not at that time such a very attractive prospect. The speed which would
have been available would be definitely faster than a human computer but
something like 100 times slower than the Manchester machine, itself one
of the slower of the modem machines. The storage was to be purely
mechanical, using wheels and cards.</li>
<li>In the nervous
system chemical phenomena are at least as important as electrical. In
certain computers the storage system is mainly acoustic. The feature of
using electricity is thus seen to be only a very superficial similarity. If we
wish to find such similarities we should look rather for mathematical
analogies of function.</li>
<li>discrete state machines</li>
<li>The prediction which we
are considering is, however, rather nearer to practicability than that
considered by Laplace. The system of the ‘universe as a whole’ is such that
quite small errors in the initial conditions can have an overwhelming effect
at a later time.</li>
<li>The displacement of a single electron by a billionth of a
centimetre at one moment might make the difference between a man being
killed by an avalanche a year later, or escaping.</li>
<li>‘The Manchester machine contains 64 magnetic
tracks each with a capacity of 2560, eight electronic tubes with a capacity
of 1280. Miscellaneous storage amounts to about 300 making a total of
174,380.’</li>
<li>The imitation game could then be
played with the machine in question (as B) and the mimicking digital
computer (as A) and the interrogator would be unable to distinguish them.</li>
<li>the digital computer must have an adequate storage capacity as
well as working sufficiently fast. Moreover, it must be programmed afresh
for each new machine which it is desired to mimic.</li>
<li>they can mimic any
discrete state machine, is described by saying that they are universal
machines. </li>
<li>I
believe that in about fifty years’ time it will be possible to programme
computers, with a storage capacity of about 10 9, to make them play the
imitation game so well that an average interrogator will not have more than
70 per cent, chance of making the right identification after five minutes of
questioning.</li>
<li>The Theological Objection. Thinking is a function of man’s
immortal soul. God has given an immortal soul to every man and woman,
but not to any other animal or to machines. Hence no animal or machine
can think.<ul>
<li>if animals
were classed with men, for there is a greater difference, to my mind,
between the typical animate and the inanimate than there is between man
and the other animals.</li>
<li>He has freedom to confer a soul on an
elephant if He sees fit? We might expect that He would only exercise this
power in conjunction with a mutation which provided the elephant with an
appropriately improved brain to minister to the needs of this soul. An
argument of exactly similar form may be made for the case of machines.</li>
</ul>
</li>
<li>When that knowledge was not
available it made a quite different impression</li>
<li>“The consequences of
machines thinking would be too dreadful. Let us hope and believe that they
cannot do so.”<ul>
<li>We like to believe
that Man is in some subtle way superior to the rest of creation. It is best if
he can be shown to be necessarily superior, for then there is no danger of
him losing his commanding position. The popularity of the theological
argument is clearly connected with this feeling. </li>
<li>The best known of these results is
known as Gödel’s theorem,1 and shows that in any sufficiently powerful
logical system statements can be formulated which can neither be proved
nor disproved within the system, unless possibly the system itself is
inconsistent.</li>
<li>We too often give wrong answers to
questions ourselves to be justified in being very pleased at such evidence
of fallibility on the part of the machines. Further, our superiority can only
be felt on such an occasion in relation to the one machine over which we
have scored our petty triumph. There would be no question of triumphing
simultaneously over all machines. In short, then, there might be men
cleverer than any given machine, but then again there might be other
machines cleverer again, and so on</li>
</ul>
</li>
<li>No mechanism could feel (and not merely
artificially signal, an easy contrivance) pleasure at its successes, grief when
its valves fuse, be warmed by flattery, be made miserable by its mistakes,
be charmed by sex, be angry or depressed when it cannot get what it wants.”</li>
<li>This argument appears to be a denial of the validity of our test.
According to the most extreme form of this view the only way by which
one could be sure that a machine thinks is to be the machine and to feel
oneself thinking. One could then describe these feelings to the world, but
of course no one would be justified in taking any notice. Likewise
according to this view the only way to know that a man thinks is to be that
particular man. </li>
<li>“I grant you that you can make machines do all the things you have
mentioned but you will never be able to make one to do X”<ul>
<li>A man has seen
thousands of machines in his lifetime. From what he sees of them he draws
a number of general conclusions. They are ugly, each is designed for a very
limited purpose, when required for a minutely different purpose they are
useless, the variety of behaviour of any one of them is very small, etc., etc.
Naturally he concludes that these are necessary properties of machines in
general. Many of these limitations are associated with the very small
storage capacity of most machines.</li>
<li>When a burnt child fears
the fire and shows that he fears it by avoiding it, I should say that he was
applying scientific induction.</li>
<li>The works and customs of mankind do not seem to
be very suitable material to which to apply scientific induction. </li>
<li>It is claimed that
the interrogator could distinguish the machine from the man simply by
setting them a number of problems in arithmetic. The machine would be
unmasked because of its deadly accuracy. The reply to this is simple. The
machine (programmed for playing the game) would not attempt to give the
right answers to the arithmetic problems. It would deliberately introduce
mistakes in a manner calculated to confuse the interrogator.</li>
<li>These abstract machines are mathematical fictions rather than
physical objects. By definition they are incapable of errors of functioning.
In this sense we can truly say that ‘machines can never make mistakes’.</li>
<li>The claim that a machine cannot be the subject of its own thought can
of course only be answered if it can be shown that the machine has some
thought with some subject matter.</li>
</ul>
</li>
<li>“The Analytical Engine has no pretensions to originate
anything. It can do whatever we know how to order it to perform”<ul>
<li>The Analytical Engine was
a universal digital computer, so that, if its storage capacity and speed were
adequate, it could by suitable programming be made to mimic the machine
in question. Probably this argument did not occur to the Countess or to
Babbage. </li>
<li>A variant of Lady Lovelace’s objection states that a machine can
‘never do anything really new’. This may be parried for a moment with the
saw, ‘There is nothing new under the sun’. Who can be certain that ‘original
work’ that he has done was not simply the growth of the seed planted in
him by teaching, or the effect of following well-known general principles.</li>
<li>The view that machines cannot give rise to surprises is due, I believe,
to a fallacy to which philosophers and mathematicians are particularly
subject. This is the assumption that as soon as a fact is presented to a mind
all consequences of that fact spring into the mind simultaneously with it. It
is a very useful assumption under many circumstances, but one too easily
forgets that it is false. A natural consequence of doing so is that one then
assumes that there is no virtue in the mere working out of consequences
from data and general principles.</li>
</ul>
</li>
<li>To attempt to provide rules of conduct to cover
every eventuality, even those arising from traffic lights, appears to be
impossible. With all this I agree.<ul>
<li>‘If each man had a definite set of rules of conduct
by which be regulated his life he would be no better than a machine. But
there are no such rules, so men cannot be machines.’</li>
<li>By ‘rules of conduct’ I mean precepts such as ‘Stop if you
see red lights’, on which one can act, and of which one can be conscious.
By ‘laws of behaviour’ I mean laws of nature as applied to a man’s body
such as ‘if you pinch him he will squeak’.</li>
<li>If we substitute ‘laws of
behaviour which regulate his life’ for ‘laws of conduct by which he
regulates his life’ in the argument quoted the undistributed middle is no
longer insuperable. For we believe that it is not only true that being
regulated by laws of behaviour implies being some sort of machine (though
not necessarily a discrete-state machine), but that conversely being such a
machine implies being regulated by such laws. </li>
<li>The only way we know of for finding such
laws is scientific observation, and we certainly know of no circumstances
under which we could say, ‘We have searched enough. There are no such
laws.’</li>
<li>Unfortunately
the statistical evidence, at least for telepathy, is overwhelming. It is very
difficult to rearrange one’s ideas so as to fit these new facts in. Once one
has accepted them it does not seem a very big step to believe in ghosts and
bogies. The idea that our bodies move simply according to the known laws
of physics, together with some others not yet discovered but somewhat
similar, would be one of the first to go</li>
</ul>
</li>
<li>that in fact one can get along very nicely if one
forgets about it.</li>
<li>The ‘skin of an onion’ analogy is also helpful. In considering the
functions of the mind or the brain we find certain operations which we can
explain in purely mechanical terms. This we say does not correspond to the
real mind: it is a sort of skin which we must strip off if we are to find the
real mind. But then in what remains we find a further skin to be stripped
off, and so on.</li>
<li>Parts of modem machines which can be
regarded as analogues of nerve cells work about a thousand times faster
than the latter. </li>
<li>This should provide a ‘margin of safety’ which could cover
losses of speed arising in many ways. Our problem then is to find out how
to programme these machines to play the game. At my present rate of
working I produce about a thousand digits of programme a day, so that
about sixty workers, working steadily through the fifty years might
accomplish the job, if nothing went into the waste-paper basket.</li>
<li>The
example of Miss Helen Keller shows that education can take place provided
that communication in both directions between teacher and pupil can take
place by some means or other.</li>
<li>We normally associate punishments and rewards with the teaching
process. Some simple child-machines can be constructed or programmed
on this sort of principle. The machine has to be so constructed that events
which shortly preceded the occurrence of a punishment-signal are unlikely
to be repeated, whereas a reward-signal increased the probability of
repetition of the events which led up to it. These definitions do not
presuppose any feelings on the part of the machine. I have done some
experiments with one such child-machine, and succeeded in teaching it a
few things, but the teaching method was too unorthodox for the experiment
to be considered really successful.</li>
<li>Alternatively one might have a complete system of
logical inference ‘built in’.1 In the latter case the store would be largely
occupied with definitions and propositions. The propositions would have
various kinds of status, e.g. well-established facts, conjectures,
mathematically proved theorems, statements given by an authority,
expressions having the logical form of proposition but not belief-value.
Certain propositions may be described as ‘imperatives’.</li>
<li>The view that ‘the machine can only do what we know how to
order it to do’,1 appears strange in face of this. Most of the programmes
which we can put into the machine will result in its doing something that
we cannot make sense of at all, or which we regard as completely random
behaviour. Intelligent behaviour presumably consists in a departure from
the completely disciplined behaviour involved in computation, but a rather
slight one, which does not give rise to random behaviour, or to pointless
repetitive loops</li>
<li>It can also be maintained that it is
best to provide the machine with the best sense organs that money can buy,
and then teach it to understand and speak English. This process could
follow the normal teaching of a child. Things would be pointed out and
named, etc. Again I do not know what the right answer is, but I think both
approaches should be tried.</li>
</ul>
        </div>
  </body>
</html>


<!-- --- -->
<!-- layout: default -->
<!-- --- -->
<!-- <a href = "/deeplearning.html">Go to index</a><br><br> -->
<!--  -->
<!--  -->
<!-- <h1>{{ page.title }}</h1> -->
<!--  -->
<!-- <span class="reading-time" title="Estimated read time"> -->
<!--   {% assign words = content | number_of_words %} -->
<!--   {% if words < 360 %} -->
<!--     <h3>Reading time : ~1 min</h3> -->
<!--   {% else %} -->
<!--     <h3>Reading time : ~{{ words | divided_by:100 }} mins</h3> -->
<!--   {% endif %} -->
<!-- </span> -->
<!--  -->
<!--  -->
<!-- <p class="view">by {{ page.author | default: site.author }}</p> -->
<!-- {% include toc.html html=content %} -->
<!-- {{ content }} -->
<!--  -->
<!-- <section> -->
<!-- Related posts:&emsp; -->
<!-- {% for p in site.related_posts %} -->
<!--   <a href={{ p.url }}> {{ p.title }}&emsp; </a> -->
<!-- {% endfor %} -->
<!--  -->
<!-- </section> -->
<!--  -->
