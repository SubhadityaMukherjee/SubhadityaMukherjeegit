<!DOCTYPE html>
<html lang="{{ site.lang | default: "en-US" }}">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    <link rel="stylesheet" href ="../assets/css/landing.css">
  </head>
  <body>
    <div class="col-md-5">
      <header>
        <h2><a id = "imp" href="../index.html">Home page</a></h2>
       
        <p>Deconstructing Deep Learning +  δeviations</p>
        
        <p>
          Drop me an <a href = "mailto: msubhaditya@gmail.com">email</a>
          Format : 
          Date | Title<br>
          &emsp;&emsp;TL; DR<br>
          <h4>Total posts : 86</h4>
          <!-- <div id="search-container"> -->
          <!--   Search for something in the blog <input type="text" id="search-input" placeholder="search..."> -->
          <!-- </div><br> -->
          <!-- <ul id="results-container"></ul> -->
        </p>
        
        
        <p class="view">
        <a href="https://www.github.com/SubhadityaMukherjee">View My GitHub Profile </a>
        </p>
      </header>
      
      <hr>
      <script src="/assets/js/search-script.js" type="text/javascript"></script>
      
      <script>
        SimpleJekyllSearch({
          searchInput: document.getElementById('search-input'),
          resultsContainer: document.getElementById('results-container'),
          json: '/assets/search.json'
        })
        </script>
    </div>
<section>
        <div class=col-md-5>
                <a href = "https://subhadityamukherjee.github.io/SubhadityaMukherjeegit/deeplearning.html">Index page</a>
                <br>

  <p><h1>My life is a lie + Even faster conv</h1>

</p>
<p>Why CNNs are Correlation Neural Networks and an even faster Convolution operation.</p>
<h2 id="corr-net">Corr Net</h2>
<p>Okay so, my life is a lie. And the operation I have been calling convolution till now is actually correlation, mathematically. But historical reasons deem that it is called Convolution. So technically, we are working with Correlation Neural Networks. Admittedly, that does not sound cool enough, so let us just stick to calling it what we did so far.</p>
<p>Anyway, today I was thinking of implementing an even more optimized convolution. This is done by first converting the image to a column. We do the same for the kernel, and follow what we did previously. And use FFT in the end as usual.</p>
<p>Okay so first, lets get what we need. Cairo and Gtk are to save the outputs directly.</p>
<pre><code class="language-julia">using Plots,Images, ImageView,TestImages, Cairo,Gtk
</code></pre>
<h2 id="im2col">Im2col</h2>
<p>Now we need to define a way to convert an image to a column vector.
We first input the block size and store it away. Do the same for the height and width of the image. 
After we have that, we create an empty array with dimensions $$m \cdot n; mc \cdot nc $$. Then we iterate over the matrix and store away the values we need.
Why do we do this? Well quite obviously, performing an operation over a single dimension will be much faster than doing it over multiple dimensions.
What is @views? This is a really cool functionality where we are actually accessing a particular part of the array without copying it to memory but modifying it. All in the name of optimization.</p>
<pre><code class="language-julia">function im2col(A, block_size) # mxn: block_size
            m,n = block_size
           M,N = size(A)
           mc = M-m+1          # no. vertical blocks
           nc = N-n+1          # no. horizontal blocks
           B = Array{eltype(A)}(undef, m*n, mc*nc)
           for j = 1:nc
             for i = 1:mc
               @views block = A[i:i+m-1, j:j+n-1]
               for k=1:m*n
                  B[k,(j-1)*mc+i] = block[k]
               end
             end
           end
           return B
       end
</code></pre>
<h2 id="col2im">Col2im</h2>
<p>Quite obviously, we need to reverse it as well. So we define col2im.
This is quite simple. We just use a reshape function with the size we want it to be in.</p>
<pre><code class="language-julia">function col2im(A,block_size)
    mm, nn = block_size
    return reshape(A, (mm, nn))
end
</code></pre>
<h2 id="tests">Tests</h2>
<p>So lets test it out!
Let us take our beloved mandrill using testimages.</p>
<p><img src="{{site.baseurl}}/assets/img/deconstrucImages/mandorig.png" alt="drawing" width="200"/></p>
<p>Then we can apply channelview on it and convert the values to Float32. Let us also just index out the 1st dimension. (since it is a colored image, there are 3 dimensions).
Then we do an im2col on it with the same dimension as that of the image.</p>
<pre><code class="language-julia">img = channelview(testimage(&quot;mandrill&quot;))[1,:,:];
img = convert.(Float32,img)
flat_im = im2col(img, (512,512));
</code></pre>
<p>Once we have that, we get an array of dimension 262144×1.</p>
<p>Now we pad the kernel using the padding function we defined before (Check the padding post) and we apply im2col to that too.</p>
<pre><code class="language-julia">kernel_padded = pad_constant(img, kernel)
flat_ker = im2col(kernel_padded, (512, 512));
</code></pre>
<p>Now both our images are of the same dimensions. We can directly apply FFT on this now.</p>
<pre><code class="language-julia">@time conv = ifft(fft(flat_im).*fft(flat_ker))
0.038521 seconds (190 allocations: 20.010 MiB)
</code></pre>
<p>Wow. Without this, it was around  0.063075 seconds (190 allocations: 76.304 MiB). Not only did it take half the time, the memory it took is so much lesser.</p>
<p>I wonder what this looks like.</p>
<pre><code class="language-julia">imshow(col2im(real.(conv),(512, 512)))

function write_to_png(guidict, filename)
    canvas = guidict[&quot;gui&quot;][&quot;canvas&quot;]
    ctx = getgc(canvas)
    Cairo.write_to_png(ctx.surface, filename)
end

write_to_png(out1, &quot;/home/subhaditya/Desktop/GITHUB/SubhadityaMukherjee.github.io/img/deconstrucImages/imconv.png&quot;)
</code></pre>
<p><img src="{{site.baseurl}}/assets/img/deconstrucImages/imconv.png" alt="drawing" width="200"/></p>
<p>Fun.</p>
        </div>
  </body>
</html>


<!-- --- -->
<!-- layout: default -->
<!-- --- -->
<!-- <a href = "/deeplearning.html">Go to index</a><br><br> -->
<!--  -->
<!--  -->
<!-- <h1>{{ page.title }}</h1> -->
<!--  -->
<!-- <span class="reading-time" title="Estimated read time"> -->
<!--   {% assign words = content | number_of_words %} -->
<!--   {% if words < 360 %} -->
<!--     <h3>Reading time : ~1 min</h3> -->
<!--   {% else %} -->
<!--     <h3>Reading time : ~{{ words | divided_by:100 }} mins</h3> -->
<!--   {% endif %} -->
<!-- </span> -->
<!--  -->
<!--  -->
<!-- <p class="view">by {{ page.author | default: site.author }}</p> -->
<!-- {% include toc.html html=content %} -->
<!-- {{ content }} -->
<!--  -->
<!-- <section> -->
<!-- Related posts:&emsp; -->
<!-- {% for p in site.related_posts %} -->
<!--   <a href={{ p.url }}> {{ p.title }}&emsp; </a> -->
<!-- {% endfor %} -->
<!--  -->
<!-- </section> -->
<!--  -->
