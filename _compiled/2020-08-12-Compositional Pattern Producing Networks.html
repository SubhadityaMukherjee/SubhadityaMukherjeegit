<!DOCTYPE html>
<html lang="{{ site.lang | default: "en-US" }}">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    <link rel="stylesheet" href ="../assets/css/landing.css">
  </head>
  <body>
    <div class="col-md-5">
      <header>
        <h2><a id = "imp" href="../index.html">Home page</a></h2>
       
        <p>Deconstructing Deep Learning +  δeviations</p>
        
        <p>
          Drop me an <a href = "mailto: msubhaditya@gmail.com">email</a>
          | RSS feed link : <a href ="https://subhadityamukherjee.github.io/feed.xml">Click</a><br>
          Format : 
          Date | Title<br>
          &emsp;&emsp;TL; DR<br>
          <h4>Total posts : 82</h4>
          <!-- <div id="search-container"> -->
          <!--   Search for something in the blog <input type="text" id="search-input" placeholder="search..."> -->
          <!-- </div><br> -->
          <!-- <ul id="results-container"></ul> -->
        </p>
        
        
        <p class="view">
        <a href="https://www.github.com/SubhadityaMukherjee">View My GitHub Profile </a>
        </p>
      </header>
      
      <hr>
      <script src="/assets/js/search-script.js" type="text/javascript"></script>
      
      <script>
        SimpleJekyllSearch({
          searchInput: document.getElementById('search-input'),
          resultsContainer: document.getElementById('results-container'),
          json: '/assets/search.json'
        })
        </script>
    </div>
<section>
        <div class=col-md-5>
                <a href = "../deeplearning.html">Index page</a>
                <br>

  <p><h1>Compositional Pattern Producing Networks</h1>

</p>
<p>Today we will talk about Compositional Pattern Producing Networks. </p>
<p>Note that Whatever I learnt about this is from <a href="https://blog.otoro.net/2016/03/25/generating-abstract-patterns-with-tensorflow/">Link to post</a> and the original Julia implementation at the model zoo. (Which I am trying to fix).</p>
<h2 id="intro">Intro</h2>
<p>Okay so what is it? Basically a CPPN is a type of generative model. Very basic but generates abstract points. How? Basically we use the neural network as a function to give us points of intensity and then we plot it. Simple as dots xD
This reminded me a lot of GANs and earlier things like identifying the latent space of an image and messing around with it.</p>
<h2 id="defining-the-parameters">Defining the parameters</h2>
<p>I do not want to blabber so let us get to the code.</p>
<p>Ah! This is like the dimensions. We define the size of the image in (x,y) and we also define the z value. N seems to be the number of input and output channels to our Dense layer (defined later). And obviously batch size as normal. </p>
<pre><code class="language-julia">z_dim = 2
x_dim = 512
y_dim = 512
N = 14
hidden = 9
batch_size = 1024
n = x_dim * y_dim

</code></pre>
<p>A small function to create an array casted between -0.5:0.5 </p>
<p>We also define the a bunch of points which would be the initial boundaries of our image. If it does not make sense, think of it as a grid. We are defining the range and filling it up with points. In x, y directions. The last one is a non linearity which I guess is something like ReLU since it seems to be a point wise operation.</p>
<p>$$rs = \sqrt{xs^{2} + ys^{2}}$$</p>
<pre><code class="language-julia">cast(x) = [range(-0.5, stop=0.5, step=1/(x - 1))...]

xs, ys = cast(x_dim), cast(y_dim)
xs = repeat(xs, inner=(y_dim))
ys = repeat(ys, outer=(x_dim))
rs = sqrt.(xs.^2 + ys.^2)
</code></pre>
<h2 id="network">Network</h2>
<p>Now we need to make a network.
We first define a Dense layer with tanh instead of relu. </p>
<p>Why? I honestly do not know. Let me run it and find out. Okay it was because it just gave barely any patterns and all white/black images. Makes sense really due to the nature of relu. I also tried it with leaky relu. Same thing.</p>
<p>Okay time to move on.</p>
<p>We then make a chain with an initial dense layer, multiple dense layers for the hidden and a final layer.</p>
<pre><code class="language-julia">unit(in=N, out=N, f=tanh) = Dense(in, out, f, initW=randn)

layers = Any[unit(3 + z_dim), [unit() for _ in 1:hidden]..., unit(N, 1, σ)]

model = Chain(layers...)
</code></pre>
<p>Now we define a tiny function which will get us the color at a point. We then write another function to batch our images so we dont blow up our GPU. I simplified and applied list comprehension where I could. #devSwag</p>
<pre><code class="language-julia">getColorAt(x) = Flux.data(model(x))

function batch(arr, s)
    l = size(arr, 2)
    batches = [arr[:, i:min(i+s-1, l)] for i=1:s:l]
    batches
end
</code></pre>
<h2 id="generation">Generation</h2>
<p>Now that we have that, on to actually generating an image.
Simply put, we create an empty grid using our x,y, z coords.
Then we use our model to predict an intensity at each point using the coordinates and we convert them to grayscale values. That way we can plot it directly as an image. 
We also reshape it to fit the size we need.</p>
<p>Thats about it.</p>
<pre><code class="language-julia">function getImage(z)
    z = repeat(reshape(z, 1, z_dim), outer=(n, 1))
    coords = hcat(xs, ys, rs, z)'
    coords = batch(coords, batch_size)
    pixels = [Gray.(hcat(getColorAt.(coords)...))...]
    reshape(pixels, y_dim, x_dim)
end
</code></pre>
<h2 id="final-image">Final Image</h2>
<p>The final part is actually plotting the image. Over here we just run the previous function and save the image locally.</p>
<pre><code class="language-julia">function saveImg(z, image_path=&quot;sample.png&quot;)
    imgg = getImage(z)
    save(image_path, imgg)
    imgg
end
</code></pre>
<p>I extended the print command to show us 10 images instead of one just to see the variation. It does look pretty. Like a bit of my personal molten steel.</p>
<pre><code class="language-julia">[saveImg(rand(z_dim)) for _ in 1:10]
</code></pre>
<p><img alt="" src="/img/cppn.png" /></p>
        </div>
  </body>
</html>


<!-- --- -->
<!-- layout: default -->
<!-- --- -->
<!-- <a href = "/deeplearning.html">Go to index</a><br><br> -->
<!--  -->
<!--  -->
<!-- <h1>{{ page.title }}</h1> -->
<!--  -->
<!-- <span class="reading-time" title="Estimated read time"> -->
<!--   {% assign words = content | number_of_words %} -->
<!--   {% if words < 360 %} -->
<!--     <h3>Reading time : ~1 min</h3> -->
<!--   {% else %} -->
<!--     <h3>Reading time : ~{{ words | divided_by:100 }} mins</h3> -->
<!--   {% endif %} -->
<!-- </span> -->
<!--  -->
<!--  -->
<!-- <p class="view">by {{ page.author | default: site.author }}</p> -->
<!-- {% include toc.html html=content %} -->
<!-- {{ content }} -->
<!--  -->
<!-- <section> -->
<!-- Related posts:&emsp; -->
<!-- {% for p in site.related_posts %} -->
<!--   <a href={{ p.url }}> {{ p.title }}&emsp; </a> -->
<!-- {% endfor %} -->
<!--  -->
<!-- </section> -->
<!--  -->
